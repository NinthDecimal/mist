mist {

  http {
    on = true
    host = "0.0.0.0"
    port = 2004
  }

  mqtt{
    on = true
    host = "rabbitmq.9dev.io"
    port = 1883
    subscribe-topic = "pca_mist_sub"
    publish-topic = "pca_mist_pub"
  }
  
  workers {
    runner = "manual" 
    cmd = """${MIST_HOME}/../../scripts/singularity start --namespace $MIST_WORKER_NAME """
    cmdStop = """${MIST_HOME}/../../scripts/singularity stop --namespace $MIST_WORKER_NAME """
    runner-init-timeout = 1960 seconds
  }
  
  context-defaults {
    downtime = 190 min
    run-options = "--repositories http://eng-01.jiwiredev.com:5050/nexus/content/repositories/jiwire,http://eng-01.jiwiredev.com:5050/nexus/content/repositories/jiwire-snapshots,http://eng-01.jiwiredev.com:5050/nexus/content/repositories/jicore --packages com.nd.location:api:1.2.9-SNAPSHOT,mysql:mysql-connector-java:6.0.5,com.jiwire:jiwire-grs:3.1.0-SNAPSHOT --exclude-packages com.jiwire:jicore --jars /usr/share/external_jars/postgresql-8.4-703.jdbc3.jar"
    worker-mode = "shared"
    spark-conf = {
      spark.cores.max = 1500
      spark.mesos.executor.memoryOverhead = 1000
      spark.executor.memory = "8100m"
      spark.ui.port = 4069
      spark.ui.showConsoleProgress = "false"
      spark.eventLog.enabled ="true"
      spark.dynamicAllocation.enabled = "false"
      spark.speculation = "true"
      spark.speculation.interval = "60s"
      spark.broadcast.compress = "true"
      spark.rdd.compress = "true"
      spark.speculation.quantile = "0.01"
      spark.speculation.multiplier = "1.1"
      spark.scheduler.mode = "FAIR"
      spark.dynamicAllocation.executorIdleTimeout = "240s"
      spark.dynamicAllocation.schedulerBacklogTimeout = "1s"
      spark.dynamicAllocation.sustainedSchedulerBacklogTimeout = "1s"
      spark.kryoserializer.buffer.max = "250m"
      spark.default.parallelism = 1000
      spark.sql.shuffle.partitions = 1000
      spark.eventLog.dir ="maprfs://mapr5-002/sas/pca/eventlog/"
    }
  }

  context {
  
    PCA_EP-Create_Ref_Tables.spark-conf = {
    
    }
  
    PCA_EP-filter_IDA_task.spark-conf = {
      
    }
  
    PCA_EP-filter_CA_events_task.spark-conf = {
      spark.speculation = "false"
    }
  
    PCA_EP-filter_events_task.spark-conf = {
      spark.speculation = "false"
    }
  
    PCA_EP-write_new_events.spark-conf = {
      spark.dynamicAllocation.enabled  = "false"
      spark.speculation = "false"
      spark.task.cpus = "1"
    }
  
    PCA_EP-filter_ref_tables.spark-conf = {
      spark.speculation = "false"
    }
  
    PCA_EP-PCA_run_task.spark-conf = {
      spark.speculation = "true"
      spark.task.cpus = "1"
      spark.network.timeout = 300000
      spark.memory.fraction = 0.15
      spark.memory.storageFraction = 0.4
    }
  
    PCA_EP-output_taskAll.spark-conf = {
      
    }
  
    PCA_EP-EventLogTracking.spark-conf = {
      spark.eventLog.enabled = "false"
    }
  
    PCA_EP-TestParaccel.spark-conf = {
      spark.cores.max = 1500
    }
    
    pca-default-exclusive {
      worker-mode = "exclusive"
      spark-conf = {
        spark.cores.max = 500
      }
    }
    
    
    pca-default-shared {
      worker-mode = "shared"
      spark-conf = {
        spark.cores.max = 500
      }
    }
  }
}
