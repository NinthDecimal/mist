mist {

  http {
    on = true
    host = "0.0.0.0"
    port = 2004
  }

  mqtt{
    on = true
    host = "rabbitmq.9dev.io"
    port = 1883
    subscribe-topic = "pca_mist_sub"
    publish-topic = "pca_mist_pub"
  }
  
  workers {
    runner = "manual" #"local"
    cmd = """${MIST_HOME}/../../scripts/singularity start --namespace $MIST_WORKER_NAME """
    cmdStop = """${MIST_HOME}/../../scripts/singularity stop --namespace $MIST_WORKER_NAME """
    runner-init-timeout = 1960 seconds
  }
  
  context-defaults {
    run-options = "--repositories http://eng-01.jiwiredev.com:5050/nexus/content/repositories/jiwire,http://eng-01.jiwiredev.com:5050/nexus/content/repositories/jiwire-snapshots,http://eng-01.jiwiredev.com:5050/nexus/content/repositories/jicore --packages com.nd.location:api:1.2.9-SNAPSHOT,mysql:mysql-connector-java:6.0.5,com.jiwire:jiwire-grs:3.1.0-SNAPSHOT --exclude-packages com.jiwire:jicore --jars /usr/share/external_jars/postgresql-8.4-703.jdbc3.jar"
    worker-mode = "exclusive"
    spark-conf = {
      spark.submit.deployMode = "cluster"
      spark.cores.max = 1500
      spark.mesos.executor.memoryOverhead = 1000
      spark.executor.memory = "8100m"
      spark.ui.port = 4069
      spark.ui.showConsoleProgress = "false"
      spark.eventLog.enabled ="true"
      spark.dynamicAllocation.enabled = "false"
      spark.speculation = "true"
      spark.speculation.interval = "60s"
      spark.broadcast.compress = "true"
      spark.rdd.compress = "true"
      spark.speculation.quantile = "0.01"
      spark.speculation.multiplier = "1.1"
      spark.scheduler.mode = "FIFO"
      spark.dynamicAllocation.executorIdleTimeout = "240s"
      spark.dynamicAllocation.schedulerBacklogTimeout = "1s"
      spark.dynamicAllocation.sustainedSchedulerBacklogTimeout = "1s"
      spark.kryoserializer.buffer.max = "250m"
      spark.default.parallelism = 1000
      spark.sql.shuffle.partitions = 1000
      spark.eventLog.dir ="maprfs://mapr5-002/sas/pca/eventlog/"
      spark.driver.memory = "8g"
      spark.executor.extraJavaOptions = "-XX:+UseParallelOldGC -XX:ParallelGCThreads=3"
      #spark.sql.warehouse.dir = ""
    }
  }

  context {
  
    hot_shared {
      worker-mode = "shared"
      downtime = Inf
      spark-conf ={
        spark.cores.max = 500
      }
    }
  
    PCA_EP-Create_Ref_Tables {
      spark-conf = {}
    }
  
    PCA_EP-filter_IDA_task {
      spark-conf = {}
    }
  
    PCA_EP-filter_CA_events_task {
      spark-conf = {
        spark.speculation = "false"
      }
    }
  
    PCA_EP-filter_events_task {
      spark-conf = {
        spark.speculation = "false"
      }
    }
  
    PCA_EP-write_new_events {
      spark-conf = {
        spark.executor.memory = "16200m"
        spark.dynamicAllocation.enabled  = "false"
        spark.speculation = "false"
        spark.task.cpus = "2"
      }
    }
  
    PCA_EP-filter_ref_tables {
      spark-conf = {
        spark.executor.memory = "16200m"
        spark.speculation = "false"
      }
    }
  
    PCA_EP-PCA_run_task {
      spark-conf = {
        spark.executor.memory = "14000m"
        spark.network.timeout = "2000s"
        #spark.speculation = "true"
        #spark.task.cpus = "1"
        #spark.memory.fraction = 0.15
        #spark.memory.storageFraction = 0.4
      }
    }
  
    PCA_EP-output_taskAll {
      spark-conf = {}
    }
  
    PCA_EP-EventLogTracking {
      spark-conf = {
        spark.eventLog.enabled = "false"
      }
    }
  
    PCA_EP-TestParaccel.spark-conf = {
      spark.cores.max = 500
    }
    
    pca-default-exclusive {
      worker-mode = "exclusive"
      spark-conf = {
        spark.cores.max = 500
      }
    }
    
    pca-default-shared {
      worker-mode = "shared"
      spark-conf = {
        spark.cores.max = 500
      }
    }
    
    pca-wrapper {
      #worker-mode = "shared"
      #downtime = 60s
      spark-conf = {
        spark.cores.max = 1
      }
    }
  }
}
